{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59e7dbd",
   "metadata": {},
   "source": [
    "The code for ILM is included in this repository, but the original and the setup instructions can be found [here](https://github.com/chrisdonahue/ilm). Before we can train the model, the compound dataset that we've created in the previous notebook needs be preprocessed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb90b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dca852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▊                                    | 1753/79146 [00:07<03:20, 386.63it/s]/Users/joanna/Documents/mva/S2/NLP/necessity-sufficiency/ilm/ilm/tokenize_util.py:182: UserWarning: Encountered empty token\n",
      "  warnings.warn('Encountered empty token')\n",
      "100%|████████████████████████████████████| 79146/79146 [04:45<00:00, 277.19it/s]\n",
      "Processed 79146 documents and created 15.640310312586864 examples per document (expected 16)\n",
      "Errors which caused retries:\n",
      "* (451890 retries) Issue with example: Mask is not unique\n",
      "* (297984 retries) Mask function exception: Tokenizer produced token not found in string\n",
      "Mask rate (characters): 0.2002\n",
      "100%|██████████████████████████████████████| 4168/4168 [00:13<00:00, 302.23it/s]\n",
      "Processed 4168 documents and created 15.692898272552783 examples per document (expected 16)\n",
      "Errors which caused retries:\n",
      "* (22460 retries) Issue with example: Mask is not unique\n",
      "* (13056 retries) Mask function exception: Tokenizer produced token not found in string\n",
      "Mask rate (characters): 0.2007\n"
     ]
    }
   ],
   "source": [
    "!sh ./ilm/create_compound_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a3891",
   "metadata": {},
   "source": [
    "Then, we can run the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55c7fee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 867405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanna/Documents/mva/S2/NLP/necessity-sufficiency/ilm/train_ilm.py:300: UserWarning: No GPU detected. Training on CPU will be very slow\n",
      "  warnings.warn('No GPU detected. Training on CPU will be very slow')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{50257: '<|startofinfill|>', 50258: '<|endofinfill|>', 50259: '<|infill_document|>', 50260: '<|infill_paragraph|>', 50261: '<|infill_sentence|>', 50262: '<|infill_ngram|>', 50263: '<|infill_word|>'}\n",
      "Loading training data\n",
      "[\":::::very likely. i think it's a good deletion, and i'm not surprised that doc did it. ) i would probably have deleted if i had not already been involved in protecting the article at the last space and if it were a little more clearly in vio of blp. like you, i didn't see it as speediable. (even in google news, the name hits 11 right now. on the web, it's got 29,600. but i don't believe wikipedia should be contributing to it, and i applaud you for ferreting it out to begin with and doc for flushing it.\"\n",
      " \"`   hi again   i really think the solar sail people are a bit optimistic about its use for interstellar travel.  the reason is just that as the acceleration is slow, you have to wait a long time, and travel a long way, to reach high speed.  at a uniform acceleration a, you reach velocity v after traveling a distance s according to   : v = sqrt(2as)  in newtonian approximation, which is applicable at the speeds we could hope to reach.  then  : s = v2/(2a)  and for a given v, s gets very large if a is small.  but since the intensity of sunlight decreases like 1/s2 with distance from the sun, a does not remain constant, but drops rapidly, making things very much worse.  once you get out to well beyond the orbit of pluto, where the sun begins to look like a very bright star, the photon drag of the light of other stars begins to become significant, as well as the cosmic background radiation, which has an energy density comparable to that of starlight.  finally there is the problem that at really high speeds, the light of the sun would begin to be red shifted, so you lose power from that effect too.  some of these problems can be solved by beaming light or microwaves out to the ship, with a huge power station (a trillion watts, say) near the earth, and a large aperture mirror to focus the beam on the ship.  then, as long as you can maintain the focal spot as small as the ship's sail, you could get constant acceleration.  a calculation i did years ago (which i will not try to reproduce now...) suggested to me that speeds of maybe  0.1c could conceivably be reached in this manner (which is very exciting) — but then, somehow, you have to stop.    (for example, if i recall, if the aperture of the beaming mirror is r, the ship sail dia r, the distance from the sun d, and the wavelength λ, then you need   : λ/r = r/d  and acceleration 10-3g will get you to 0.03c in 30 years, at a distance d of 0.5 light years, 1018/2 cm, which makes the mirror r ~ 50 km in diameter for a sail r 100 km, with a 1 um λ.  nb the mirror needs to be optically perfect to << λ, but the sail does not.)  of course 0.1c is a useful speed, and you might split the problem between a beamed laser sailer, with a fusion rocket to stop, but the trillion watt figure i remember was for a fairly small ship, 100 or 1000 tons if i recall, and i think a nuclear-electric ship capable of reaching even a few percent of c is going to be much larger than that for a payload of 100 or 1000 tons.  i cannot imagine a decade ship smaller than an aircraft carrier, so it sounds like a pretty tough way to go, though possibly competitive with other approaches.    what i personally think we need to do is work the problem modestly hard from an engineering standpoint, considering all approaches, producing realistic design mission studies that give us the best trade-off solution with current technology.  right now the trip time, for a program we could realistically sell to the combined economies of the planet, would probably last a thousand years or more.  so in ten or thirty years we should redo the study, and see how that number has changed due to technological advances.  at some point the curve of reasonable trip times will either get down to the order of the time between studies, or else it will flatten out when we hit the wall of feasible engineering.  or maybe there will be a huge breakthrough when somebody figures out how to create a wormhole to a nearby star, or something equally revolutionary.  anyhow, only when the trip time is getting down to the time between studies (which would depend on the rate of technology change) would it be sensible to start a serious program, with what nasa would call a ``phase a study``, leading to a program start, then a preliminary design review, and then a critical design review,... which is when you can start cutting metal.   solar sailing is probably a competitive way of getting around the solar system, though i think nuclear-electric ion drives are likely to prove better.  the latter can certainly take us all over the solar system in the time scales of the great explorations of the 15th and 16th centuries.  then in 500 years the solar system will be ours, and we will have a far better idea of exactly what is out there in the dark between the stars, possibly mini-solar systems like jupiter & its moons.  if such systems are common, we might find useful places to go only 1% as far as alpha centauri, which would change everything.  and the human species would be safe at last from the many disasters which threaten us now.    sorry i have been inattentive to wikipedia for a month or two, due to other responsibilities, which may increase or diminish in\"\n",
      " \"`  as i recall, the ``classic 6`` teams were in a league that operated like a country club. they nearly got caught napping, but they headed off the second-major-league threat by expanding... which of course brought in a bunch of money to the old guard from the entrance fees. also, they aligned the new teams in a separate division, which essentially made the stanley cup finals an exhibition series for the winners of the ``classic 6`` playoff rounds. further evolution of the league evened out a lot of that stuff, of course, but there's some intrigue connected with their initial expansion. i noticed there were many references to ``norris house league`` in google, so it's not like this is unknown. maybe the comment could be written better and/or with more detail, but it's an important part of the nature of the nhl as it existed during that time period.  '''' `\"\n",
      " ...\n",
      " \":what behavior? i protested a number of afds concerned with academics. the nominator offered nothing but their personal opinion and is aggressively afding a lot of academics, then comes to an/i and says i am hounding him/her without any diffs or proof, but everything anyone said against me is taken 100%? and with that you advise me to, well, to drop what? i am not hounding anyone at the bot related pages. betacommand is stalking me there. so, you're saying, as long as i let everyone who disagrees with me do what they want that, that what? i can't even follow this?  :i can just make accusations against another user and provide no proof and the accusations will be believed? even a user with as tarnished a history as betacommand can make an unsupported accusation against me and you'll believe it? why would i take your advice? the block removal was pointless because the ip is blocked, you know.   :if you're going to accuse me of things, why not provide proof, support your accusations, demand that others support your accusations, then give me 1/2 a chance to defend myself against the accusations instead of just assuming because i'm new that anything anyone says against me is 100% accurate and nothing i can say even if the accusations were presented would matter?\"\n",
      " \"== gen y begins in 1978 ==  gen y definitely begins in 1978. a previous author was right when she mentioned that people born in that era (1978-1984) are pretty in between, the same way people born in the early 1960s are between the classic generation x and the classic baby boom.  i think there is a difference between early generation yers (1978-1984) and late generation yers (1985-1994) but i don't think people born after about 1993 or 1994 can be included in generation y. part of being gen y is being a child of a baby boomer. my parents were born in 1955 and i was born in 1990. the baby boomers are a pretty unified generation, and even my parents consider themselves to be part of a different generation than people born in the 1940s. my parents are children of the '70s, watergate era, and came of age as adults during the late 1970s and early 1980s yuppie/disco era. meanwhile, someone born in 1946 remembers the conformity of the 1960s and was in high school as opposed to grade school during the jfk assassination, and could have been drafted for vietnam. they were old enough to take part in the antiwar protests or go to woodstock. after about 1954 the boomers were children of the '70s, while before they were children of the '60s.  the same distinction exists between early and late y. early y is a transitional group between generation x and generation y, and their coming-of-age was characterized by alot of change (pcs, etc.) also, their parents included more vietnam vets and protestors, and hippies, while most people my age have parents whose adolescent preoccupations were disco and led zeppelin-type rock, watergate and the oil crisis.  i really don't think most people in gen x would be too comfortable with people who were little kids in the '80s being in their generation. being an adolescent in the 1980s is a generation x requirement.\"\n",
      " 'where can i read the vandalism site? please tell me! thank you!']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/joanna/Documents/mva/S2/NLP/necessity-sufficiency/ilm/train_ilm.py\", line 787, in <module>\n",
      "    train(args)\n",
      "  File \"/Users/joanna/Documents/mva/S2/NLP/necessity-sufficiency/ilm/train_ilm.py\", line 366, in train\n",
      "    train_tt_to_count = {TargetType(k):v for k, v in zip(*np.unique(train_tts, return_counts=True))}\n",
      "  File \"/Users/joanna/Documents/mva/S2/NLP/necessity-sufficiency/ilm/train_ilm.py\", line 366, in <dictcomp>\n",
      "    train_tt_to_count = {TargetType(k):v for k, v in zip(*np.unique(train_tts, return_counts=True))}\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py\", line 384, in __call__\n",
      "    return cls.__new__(cls, value)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/enum.py\", line 702, in __new__\n",
      "    raise ve_exc\n",
      "ValueError: np.str_('') is not a valid TargetType\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'DATASET=compound_dataset\\nTRAIN_DIR=../Models/ILM\\nEXAMPLES_DIR=Data/char_masks/${DATASET}\\npython ilm/train_ilm.py \\\\\\n\\texperiment_${DATASET} \\\\\\n\\t${TRAIN_DIR} \\\\\\n\\t${EXAMPLES_DIR} \\\\\\n\\t--train_examples_tag train \\\\\\n\\t--eval_examples_tag valid \\\\\\n\\t--train_num_epochs 4 \\\\\\n\\t--eval_max_num_examples 512\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDATASET=compound_dataset\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mTRAIN_DIR=../Models/ILM\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mEXAMPLES_DIR=Data/char_masks/$\u001b[39;49m\u001b[38;5;132;43;01m{DATASET}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mpython ilm/train_ilm.py \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mexperiment_$\u001b[39;49m\u001b[38;5;132;43;01m{DATASET}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{TRAIN_DIR}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;132;43;01m{EXAMPLES_DIR}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m--train_examples_tag train \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m--eval_examples_tag valid \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m--train_num_epochs 4 \u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m--eval_max_num_examples 512\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mva/S2/NLP/necessity-sufficiency/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2517\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2516\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2517\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Documents/mva/S2/NLP/necessity-sufficiency/.venv/lib/python3.9/site-packages/IPython/core/magics/script.py:154\u001b[0m, in \u001b[0;36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     line \u001b[38;5;241m=\u001b[39m script\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mva/S2/NLP/necessity-sufficiency/.venv/lib/python3.9/site-packages/IPython/core/magics/script.py:314\u001b[0m, in \u001b[0;36mScriptMagics.shebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mraise_error \u001b[38;5;129;01mand\u001b[39;00m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[1;32m    313\u001b[0m     rc \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'DATASET=compound_dataset\\nTRAIN_DIR=../Models/ILM\\nEXAMPLES_DIR=Data/char_masks/${DATASET}\\npython ilm/train_ilm.py \\\\\\n\\texperiment_${DATASET} \\\\\\n\\t${TRAIN_DIR} \\\\\\n\\t${EXAMPLES_DIR} \\\\\\n\\t--train_examples_tag train \\\\\\n\\t--eval_examples_tag valid \\\\\\n\\t--train_num_epochs 4 \\\\\\n\\t--eval_max_num_examples 512\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATASET=compound_dataset\n",
    "TRAIN_DIR=../Models/ILM\n",
    "EXAMPLES_DIR=Data/char_masks/${DATASET}\n",
    "python ilm/train_ilm.py \\\n",
    "\texperiment_${DATASET} \\\n",
    "\t${TRAIN_DIR} \\\n",
    "\t${EXAMPLES_DIR} \\\n",
    "\t--train_examples_tag train \\\n",
    "\t--eval_examples_tag valid \\\n",
    "\t--train_num_epochs 4 \\\n",
    "\t--eval_max_num_examples 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
