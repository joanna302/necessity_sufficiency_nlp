{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joanna/Documents/mva/S2/NLP/project_nlp/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "\n",
    "import ilm.ilm.tokenize_util\n",
    "from ilm.ilm.infer import infill_with_ilm\n",
    "from perturbation_functions import calculate_necc_and_suff, gen_num_samples_table, gen_probs_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<|startofinfill|>': 50257, '<|endofinfill|>': 50258, '<|infill_document|>': 50259, '<|infill_paragraph|>': 50260, '<|infill_sentence|>': 50261, '<|infill_ngram|>': 50262, '<|infill_word|>': 50263}\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = 'Models/ILM/'\n",
    "MASK_CLS = 'ilm.mask.hierarchical.MaskHierarchical'\n",
    "\n",
    "tokenizer = ilm.ilm.tokenize_util.Tokenizer.GPT2\n",
    "with open(os.path.join(MODEL_DIR, 'additional_ids_to_tokens.pkl'), 'rb') as f:\n",
    "    additional_ids_to_tokens = pickle.load(f)\n",
    "additional_tokens_to_ids = {v:k for k, v in additional_ids_to_tokens.items()}\n",
    "try:\n",
    "    ilm.ilm.tokenize_util.update_tokenizer(additional_ids_to_tokens, tokenizer)\n",
    "except ValueError:\n",
    "    print('Already updated')\n",
    "print(additional_tokens_to_ids)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#model = GPT2LMHeadModel.from_pretrained(MODEL_DIR)\n",
    "config = GPT2Config.from_json_file(f'{MODEL_DIR}config.json')\n",
    "model = GPT2LMHeadModel(config)\n",
    "# Charger les poids\n",
    "model.load_state_dict(torch.load(f'{MODEL_DIR}model_weights.pt', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [45:17:39<00:00, 1358.83s/it]  \n"
     ]
    }
   ],
   "source": [
    "# generate approximately 100 perturbations for each token. \n",
    "num_samples = gen_num_samples_table(50, 100)\n",
    "probs_table = gen_probs_table(50)\n",
    "mask_tokn = additional_tokens_to_ids['<|infill_ngram|>']\n",
    "\n",
    "orig_texts = []\n",
    "necc_perturbed = []\n",
    "suff_perturbed = []\n",
    "necc_masks = []\n",
    "suff_masks = []\n",
    "\n",
    "with open(\"extension_sexism/data_sexism/samples_sexism.txt\", \"r\") as ff:\n",
    "    with tqdm(total=120) as pbar:\n",
    "        for text in ff:\n",
    "            necc_pp, suff_pp, necc_mm, suff_mm = calculate_necc_and_suff(text, ilm_tokenizer=tokenizer, ilm_model=model, cl_tokenizer=None, cl_model=None, num_samples=num_samples,\n",
    "                               mask_tokn=mask_tokn, additional_tokens_to_ids=additional_tokens_to_ids, probs_table=probs_table, \n",
    "                               return_pert_only=True)\n",
    "\n",
    "            orig_texts.append(text)\n",
    "            necc_perturbed.append(necc_pp)\n",
    "            suff_perturbed.append(suff_pp)\n",
    "            necc_masks.append(necc_mm)\n",
    "            suff_masks.append(suff_mm)\n",
    "            pbar.update(1)\n",
    "    \n",
    "necc_suff_perturbations = {'orig_texts': orig_texts, \n",
    "                           'necc_perturbed': necc_perturbed, \n",
    "                           'suff_perturbed': suff_perturbed,\n",
    "                           'necc_masks': necc_masks,\n",
    "                           'suff_masks': suff_masks}\n",
    "\n",
    "pickle.dump(necc_suff_perturbations, open('extension_sexism/data_sexism/sexism_necc_suff_perturbations.pickle', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
