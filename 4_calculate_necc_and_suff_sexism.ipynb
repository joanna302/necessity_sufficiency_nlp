{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6b9f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from random import shuffle\n",
    "from perturbation_functions import get_preds_and_scores, calc_suff, calc_necc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e4dd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['orig_texts', 'necc_perturbed', 'suff_perturbed', 'necc_masks', 'suff_masks'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perts = pickle.load(open(\"extension_sexism/data_sexism/sexism_necc_suff_perturbations.pickle\",\"rb\"))\n",
    "perts['orig_texts'] = [tt.strip(' \\n') for tt in perts['orig_texts']]\n",
    "perts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b9c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# add special tokens for URLs, emojis and mentions (--> see pre-processing)\n",
    "special_tokens_dict = {'additional_special_tokens': ['[USER]','[EMOJI]','[URL]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "dataset='extension_sexism/data_sexism'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a000c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying HateCheck perturbations with extension_sexism/data_sexism.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee14edb59762471fbb3dde17ebb7a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/91568 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "orig_preds = {}\n",
    "orig_scores = {}\n",
    "necc_preds = {}\n",
    "necc_scores = {}\n",
    "suff_preds = {}\n",
    "suff_scores = {}\n",
    "\n",
    "\n",
    "print(\"Classifying HateCheck perturbations with {}.\".format(dataset))\n",
    "model = BertForSequenceClassification.from_pretrained(f\"extension_sexism/Model/data_sexism_2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()\n",
    "\n",
    "total_len = len(perts['orig_texts']) + sum(len(nn) for nn in perts['necc_perturbed']) + sum(len(nn) for nn in perts['suff_perturbed'])\n",
    "\n",
    "with tqdm(total=total_len) as pbar:\n",
    "    orig_preds[dataset], orig_scores[dataset] = get_preds_and_scores(perts['orig_texts'], tokenizer, model, pbar)\n",
    "    \n",
    "    necc_preds[dataset] = []\n",
    "    necc_scores[dataset] = []\n",
    "\n",
    "    for tt in perts['necc_perturbed']:\n",
    "        pp, ss = get_preds_and_scores(tt, tokenizer, model, pbar)\n",
    "        necc_preds[dataset].append(pp)\n",
    "        necc_scores[dataset].append(ss)\n",
    "        \n",
    "    suff_preds[dataset] = []\n",
    "    suff_scores[dataset] = []\n",
    "\n",
    "    for tt in perts['suff_perturbed']:\n",
    "        pp, ss = get_preds_and_scores(tt, tokenizer, model, pbar)\n",
    "        suff_preds[dataset].append(pp)\n",
    "        suff_scores[dataset].append(ss)\n",
    "            \n",
    "        \n",
    "final_results = {\n",
    "                'orig_preds': orig_preds,\n",
    "                'orig_scores': orig_scores,\n",
    "                'necc_preds': necc_preds,\n",
    "                'necc_scores': necc_scores,\n",
    "                'suff_preds': suff_preds,\n",
    "                'suff_scores': suff_scores,\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4837fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mfinal_results\u001b[49m, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/HateCheck_necc_suff_preds.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_results' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(final_results, open(\"extension_sexism/sexism_necc_suff_preds.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pickle.load(open(\"extension_sexism/sexism_necc_suff_preds.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/ILM/compound_dataset/train.txt\", \"r\") as ff:\n",
    "    compound_dataset = ff.read().split(\"\\n\\n\\n\")\n",
    "compound_dataset = [tt.strip(\" :`.,\") for tt in compound_dataset]\n",
    "shuffle(compound_dataset)\n",
    "compound_dataset = compound_dataset[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e0a6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82144fb56b234034a7f7619f0d76549d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_preds = {}\n",
    "baseline_scores = {}\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"extension_sexism/Model/data_sexism_2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()\n",
    "preds, scores = get_preds_and_scores(compound_dataset, tokenizer, model)\n",
    "baseline_preds[dataset] = sum(preds)/len(preds)\n",
    "baseline_scores[dataset] = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({'baseline_preds':baseline_preds, 'baseline_scores':baseline_scores}, open(\"Classifier_sexism_baselines.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "necc_results = {}\n",
    "necc_results_nb = {}\n",
    "suff_results = {}\n",
    "suff_results_nb = {}\n",
    "\n",
    "    \n",
    "## NECCESSITY CALCULATIONS\n",
    "neccs = []\n",
    "for oo, pp, mm in zip(final_results['orig_preds'][dataset], \n",
    "                        final_results['necc_preds'][dataset], \n",
    "                        perts['necc_masks']):\n",
    "    pp = np.array(pp)\n",
    "    neccs.append(calc_necc(oo, pp, mm))\n",
    "necc_results[dataset] = neccs \n",
    "\n",
    "neccs_nb = []\n",
    "for oo, pp, mm in zip(final_results['orig_scores'][dataset], \n",
    "                        final_results['necc_scores'][dataset], \n",
    "                        perts['necc_masks']):\n",
    "    pp = np.array(pp)\n",
    "    neccs_nb.append(calc_necc(oo, pp, mm))\n",
    "necc_results_nb[dataset] = neccs_nb\n",
    "\n",
    "## SUFFICIENCY CALCULATIONS\n",
    "baseline_pred = baseline_preds[dataset]\n",
    "baseline_score = baseline_scores[dataset]\n",
    "\n",
    "suffs = []\n",
    "for pp, mm in zip(final_results['suff_preds'][dataset], perts['suff_masks']):\n",
    "    pp = np.array(pp)\n",
    "    suffs.append(calc_suff(baseline_pred, pp, mm))\n",
    "suff_results[dataset] = suffs \n",
    "\n",
    "suffs_nb = []\n",
    "for pp, mm in zip(final_results['suff_scores'][dataset], perts['suff_masks']):\n",
    "    pp = np.array(pp)\n",
    "    suffs_nb.append(calc_suff(baseline_score, pp, mm))\n",
    "suff_results_nb[dataset] = suffs_nb     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23175599",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_necc_suff_results = {\n",
    "    'necc_results': necc_results,\n",
    "    'necc_results_nb': necc_results_nb,\n",
    "    'suff_results': suff_results, \n",
    "    'suff_results_nb': suff_results_nb\n",
    "}\n",
    "\n",
    "pickle.dump(hatecheck_necc_suff_results, open('Data/HateCheck_necc_suff_results_all.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a850153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now get the predictions for all models for the entire hatecheck suite\n",
    "hc_test_cases_all = pd.read_csv(\"Data/hatecheck-data/test_suite_cases.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hc_test_cases_all = hc_test_cases_all.test_case.tolist()\n",
    "hc_preds = {}\n",
    "hc_scores = {}\n",
    "for dataset in datasets: \n",
    "    model = BertForSequenceClassification.from_pretrained(\"Model/{}\".format(dataset))\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model.eval()\n",
    "    preds, scores = get_preds_and_scores(hc_test_cases_all, tokenizer, model)\n",
    "    hc_preds[dataset] = preds\n",
    "    hc_scores[dataset] = scores\n",
    "\n",
    "pickle.dump({'preds': hc_preds, 'scores':hc_scores}, open('Data/HateCheck_results_all_models.pickle', \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19e934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    hc_test_cases_all['{}_pred'.format(dataset)] = hc_preds[dataset]\n",
    "    hc_test_cases_all['{}_score'.format(dataset)] = hc_scores[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31924981",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hc_test_cases_all, open('Data/HateCheck_templates_and_results.pickle', \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
